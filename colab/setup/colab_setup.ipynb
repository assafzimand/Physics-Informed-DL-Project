{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üåä Wave Source Localization - Colab Setup\n",
        "\n",
        "**Run this notebook first in every Colab session!**\n",
        "\n",
        "This notebook will:\n",
        "- ‚úÖ Set up the environment\n",
        "- ‚úÖ Install dependencies \n",
        "- ‚úÖ Mount Google Drive\n",
        "- ‚úÖ Sync latest code from GitHub\n",
        "- ‚úÖ Verify dataset availability\n",
        "- ‚úÖ Configure MLflow\n",
        "\n",
        "**Estimated time: 3-5 minutes**\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. üîß Environment Setup & GPU Check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "\n",
        "print(\"üñ•Ô∏è  System Information:\")\n",
        "print(f\"   Python: {sys.version}\")\n",
        "print(f\"   PyTorch: {torch.__version__}\")\n",
        "print(f\"   CUDA Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"   GPU: {gpu_name}\")\n",
        "    print(f\"   GPU Memory: {gpu_memory:.1f} GB\")\n",
        "    print(\"\\n‚úÖ GPU is available! Training will be fast.\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  No GPU detected. Go to Runtime > Change runtime type > GPU\")\n",
        "\n",
        "# Set device for later use\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\nüéØ Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. üì¶ Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q mlflow h5py PyYAML tqdm matplotlib seaborn scikit-learn\n",
        "\n",
        "print(\"‚úÖ All dependencies installed successfully!\")\n",
        "\n",
        "# Verify installations\n",
        "try:\n",
        "    import mlflow\n",
        "    import h5py\n",
        "    import yaml\n",
        "    import tqdm\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import sklearn\n",
        "    print(\"‚úÖ All imports successful!\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. üíæ Mount Google Drive & Setup Directories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create project directory structure in Drive if it doesn't exist\n",
        "project_drive_path = '/content/drive/MyDrive/Physics_Informed_DL_Project'\n",
        "os.makedirs(project_drive_path, exist_ok=True)\n",
        "os.makedirs(f'{project_drive_path}/datasets', exist_ok=True)\n",
        "os.makedirs(f'{project_drive_path}/results', exist_ok=True)\n",
        "os.makedirs(f'{project_drive_path}/models', exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Google Drive mounted at: {project_drive_path}\")\n",
        "print(f\"üìÅ Directory structure created in Drive\")\n",
        "\n",
        "# Check for dataset\n",
        "dataset_path = f'{project_drive_path}/datasets/wave_dataset_T500.h5'\n",
        "if os.path.exists(dataset_path):\n",
        "    file_size = os.path.getsize(dataset_path) / 1e6\n",
        "    print(f\"üìä Found dataset: wave_dataset_T500.h5 ({file_size:.1f} MB)\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Dataset not found. Upload wave_dataset_T500.h5 to:\")\n",
        "    print(f\"   {project_drive_path}/datasets/\")\n",
        "\n",
        "# Save paths for other notebooks\n",
        "DRIVE_PROJECT_PATH = project_drive_path\n",
        "DATASET_PATH = dataset_path\n",
        "print(f\"\\\\nüîó Paths configured for session\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. üéâ Setup Complete - Next Steps\n",
        "\n",
        "**üéØ Your Colab environment is ready!**\n",
        "\n",
        "### What you can do now:\n",
        "\n",
        "1. **Upload Dataset** (if not done yet):\n",
        "   - Use the local script: `python colab/data/upload_dataset.py`\n",
        "   - Or manually copy `wave_dataset_T500.h5` to Drive\n",
        "\n",
        "2. **Run Experiments**:\n",
        "   - Quick single experiment: Open `colab/notebooks/quick_training.ipynb`\n",
        "   - Batch experiments: Open `colab/notebooks/batch_training.ipynb`\n",
        "\n",
        "3. **Monitor Progress**:\n",
        "   - Training metrics will be logged to MLflow\n",
        "   - Results auto-download after each session\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
