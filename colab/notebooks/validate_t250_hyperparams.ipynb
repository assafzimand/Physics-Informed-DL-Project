{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üß™ T=250 Dataset Hyperparameter Validation\n",
        "\n",
        "**Objective**: Validate winning hyperparameters on T=250 dataset with single-fold training before committing to full 5-fold CV.\n",
        "\n",
        "- **Dataset**: T=250 (wave_dataset_T250.h5)\n",
        "- **Hyperparameters**: lr=0.001, batch_size=32, adam optimizer\n",
        "- **Training**: 1 fold, 50 epochs (~2 hours)\n",
        "- **Goal**: Quick validation before 10-hour full CV investment\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîß Environment Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"üöÄ PyTorch version: {torch.__version__}\")\n",
        "print(f\"üî• CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üì± GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Navigate to project directory and clone/update repo\n",
        "import os\n",
        "project_path = '/content/drive/MyDrive/Colab Notebooks/Physics Informed DL Project'\n",
        "\n",
        "# Clone or update repository\n",
        "if not os.path.exists(project_path):\n",
        "    print(\"üîÑ Cloning repository...\")\n",
        "    !git clone https://github.com/assafch/physics_informed_dl_project.git \"$project_path\"\n",
        "else:\n",
        "    print(\"üîÑ Updating repository...\")\n",
        "    os.chdir(project_path)\n",
        "    !git pull origin main\n",
        "\n",
        "os.chdir(project_path)\n",
        "print(f\"üìÅ Working directory: {os.getcwd()}\")\n",
        "\n",
        "# Verify project structure\n",
        "key_dirs = ['src', 'configs', 'data', 'experiments']\n",
        "for dir_name in key_dirs:\n",
        "    if os.path.exists(dir_name):\n",
        "        print(f\"‚úÖ {dir_name}/ found\")\n",
        "    else:\n",
        "        print(f\"‚ùå {dir_name}/ missing\")\n",
        "        \n",
        "print(\"\\nüìÇ Repository ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install/update requirements\n",
        "%pip install -q -r requirements.txt\n",
        "%pip install -q mlflow\n",
        "\n",
        "print(\"‚úÖ Dependencies installed\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìä Dataset Verification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if T=250 dataset exists\n",
        "from pathlib import Path\n",
        "\n",
        "dataset_path = \"data/wave_dataset_T250.h5\"\n",
        "if Path(dataset_path).exists():\n",
        "    file_size = Path(dataset_path).stat().st_size / (1024**3)  # GB\n",
        "    print(f\"‚úÖ Dataset found: {dataset_path}\")\n",
        "    print(f\"üì¶ File size: {file_size:.1f} GB\")\n",
        "else:\n",
        "    print(f\"‚ùå Dataset not found: {dataset_path}\")\n",
        "    print(\"\\nüîç Available datasets:\")\n",
        "    for file in Path(\"data\").glob(\"*.h5\"):\n",
        "        size = file.stat().st_size / (1024**3)\n",
        "        print(f\"   {file.name} ({size:.1f} GB)\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üöÄ Validation Training Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Add project to path\n",
        "sys.path.append('.')\n",
        "\n",
        "from src.training.trainer import WaveTrainer\n",
        "from configs.training_config import TrainingConfig\n",
        "\n",
        "print(\"üß™ T=250 Dataset Hyperparameter Validation\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"üïê Start time: {datetime.now().strftime('%H:%M:%S')}\")\n",
        "print(\"‚è±Ô∏è Expected duration: ~2 hours\")\n",
        "print(\"üéØ Goal: Validate hyperparameters before full 5-fold CV\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create validation configuration using winning hyperparameters\n",
        "config = TrainingConfig(\n",
        "    # Winning hyperparameters from T=500 grid search\n",
        "    learning_rate=0.001,\n",
        "    batch_size=32,\n",
        "    optimizer=\"adam\",\n",
        "    weight_decay=0.01,\n",
        "    \n",
        "    # Dataset configuration\n",
        "    dataset_path=\"data/wave_dataset_T250.h5\",\n",
        "    train_split=0.8,\n",
        "    val_split=0.2,\n",
        "    \n",
        "    # Training configuration - validation run\n",
        "    num_epochs=50,  # Quick validation\n",
        "    early_stopping_patience=15,\n",
        "    \n",
        "    # Model configuration\n",
        "    model_name=\"WaveSourceMiniResNet\",\n",
        "    grid_size=128,\n",
        "    \n",
        "    # Training settings\n",
        "    device=\"cuda\",\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        "    \n",
        "    # Scheduler\n",
        "    scheduler_type=\"plateau\",\n",
        "    scheduler_patience=5,\n",
        "    \n",
        "    # Logging and saving\n",
        "    experiment_name=\"t250_hyperparams_validation\",\n",
        "    run_name=f\"validation_lr001_bs32_adam_50epochs_{datetime.now().strftime('%Y%m%d_%H%M')}\",\n",
        "    save_model_every_n_epochs=25,\n",
        "    \n",
        "    # Random seed for reproducibility\n",
        "    random_seed=42\n",
        ")\n",
        "\n",
        "print(\"üîß Validation Configuration:\")\n",
        "print(f\"   Dataset: T=250 ({config.dataset_path})\")\n",
        "print(f\"   Hyperparameters: lr={config.learning_rate}, bs={config.batch_size}, opt={config.optimizer}\")\n",
        "print(f\"   Epochs: {config.num_epochs}\")\n",
        "print(f\"   Expected time: ~2 hours\")\n",
        "print(f\"   Device: {config.device}\")\n",
        "print(f\"   Run name: {config.run_name}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üèÉ‚Äç‚ôÇÔ∏è Run Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and run trainer\n",
        "trainer = WaveTrainer(config)\n",
        "\n",
        "print(\"\\nüöÄ Starting validation training...\")\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    # Train the model\n",
        "    training_history = trainer.train()\n",
        "    \n",
        "    end_time = time.time()\n",
        "    training_duration = (end_time - start_time) / 60  # Convert to minutes\n",
        "    \n",
        "    print(f\"\\n‚è±Ô∏è Training completed in {training_duration:.1f} minutes\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Training failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìä Results Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract and analyze results\n",
        "if 'training_history' in locals():\n",
        "    final_train_loss = training_history['train_loss'][-1]\n",
        "    final_val_loss = training_history['val_loss'][-1]\n",
        "    final_val_distance_error = training_history['val_distance_error'][-1]\n",
        "    best_epoch = training_history.get('best_epoch', len(training_history['val_loss']))\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"üéâ VALIDATION TRAINING COMPLETE!\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    print(f\"‚è±Ô∏è Training Time: {training_duration:.1f} minutes\")\n",
        "    print(f\"üèÜ Best Epoch: {best_epoch}\")\n",
        "    print(f\"üìä Final Results:\")\n",
        "    print(f\"   Training Loss: {final_train_loss:.4f}\")\n",
        "    print(f\"   Validation Loss: {final_val_loss:.4f}\")\n",
        "    print(f\"   Distance Error: {final_val_distance_error:.3f} px\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "    # Performance assessment (continuing from previous cell)\n",
        "    if 'final_val_distance_error' in locals():\n",
        "        print(f\"\\nüìà Performance Assessment:\")\n",
        "        if final_val_distance_error <= 2.0:\n",
        "            print(f\"   ‚úÖ EXCELLENT: {final_val_distance_error:.3f} px (‚â§ 2.0 px)\")\n",
        "            recommendation = \"‚úÖ RECOMMENDED: Proceed with full 5-fold CV training\"\n",
        "        elif final_val_distance_error <= 3.0:\n",
        "            print(f\"   ‚úÖ GOOD: {final_val_distance_error:.3f} px (‚â§ 3.0 px)\")\n",
        "            recommendation = \"‚úÖ RECOMMENDED: Proceed with full 5-fold CV training\"\n",
        "        elif final_val_distance_error <= 4.0:\n",
        "            print(f\"   ‚ö†Ô∏è ACCEPTABLE: {final_val_distance_error:.3f} px (‚â§ 4.0 px)\")\n",
        "            recommendation = \"‚ö†Ô∏è CONSIDER: Maybe adjust hyperparameters or proceed with caution\"\n",
        "        else:\n",
        "            print(f\"   ‚ùå CONCERNING: {final_val_distance_error:.3f} px (> 4.0 px)\")\n",
        "            recommendation = \"‚ùå RECOMMEND: Consider hyperparameter tuning before full CV\"\n",
        "        \n",
        "        # Comparison with T=500 results\n",
        "        print(f\"\\nüîÑ Comparison with T=500 Results:\")\n",
        "        print(f\"   T=500 Grid Search Best: 2.37 px\")\n",
        "        print(f\"   T=500 CV Average: 2.078 px\")\n",
        "        print(f\"   T=250 Validation: {final_val_distance_error:.3f} px\")\n",
        "        \n",
        "        if final_val_distance_error < 2.5:\n",
        "            print(\"   ‚úÖ T=250 performance is competitive with T=500!\")\n",
        "        elif final_val_distance_error < 3.5:\n",
        "            print(\"   ‚úÖ T=250 performance is reasonable compared to T=500\")\n",
        "        else:\n",
        "            print(\"   ‚ö†Ô∏è T=250 performance is worse than T=500 - consider investigation\")\n",
        "        \n",
        "        print(f\"\\nüéØ RECOMMENDATION:\")\n",
        "        print(f\"   {recommendation}\")\n",
        "        \n",
        "        if \"RECOMMENDED\" in recommendation:\n",
        "            print(f\"\\nüöÄ Next Steps:\")\n",
        "            print(f\"   1. Run full 5-fold CV training on T=250 dataset\")\n",
        "            print(f\"   2. Use same hyperparameters: lr=0.001, bs=32, adam\")\n",
        "            print(f\"   3. Expected full CV time: ~10 hours\")\n",
        "            print(f\"   4. Expected CV performance: ~{final_val_distance_error:.1f} ¬± 0.3 px\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üéâ Validation complete! Check results above for next steps.\")\n",
        "else:\n",
        "    print(\"‚ùå No training history available - training may have failed\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìà Training Curves & Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'training_history' in locals():\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    \n",
        "    # Loss curves\n",
        "    epochs = range(1, len(training_history['train_loss']) + 1)\n",
        "    axes[0].plot(epochs, training_history['train_loss'], 'b-', label='Training Loss', alpha=0.8)\n",
        "    axes[0].plot(epochs, training_history['val_loss'], 'r-', label='Validation Loss', alpha=0.8)\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].set_title('T=250 Validation: Loss Curves')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Distance error\n",
        "    axes[1].plot(epochs, training_history['val_distance_error'], 'g-', label='Distance Error', alpha=0.8)\n",
        "    axes[1].axhline(y=2.0, color='orange', linestyle='--', alpha=0.7, label='Target (2.0 px)')\n",
        "    axes[1].axhline(y=2.078, color='purple', linestyle='--', alpha=0.7, label='T=500 CV Avg')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Distance Error (px)')\n",
        "    axes[1].set_title('T=250 Validation: Distance Error')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Summary\n",
        "    axes[2].text(0.5, 0.7, f'Final Results', ha='center', va='center', transform=axes[2].transAxes, \n",
        "                fontsize=14, fontweight='bold')\n",
        "    axes[2].text(0.5, 0.5, f'Distance Error: {final_val_distance_error:.3f} px', \n",
        "                ha='center', va='center', transform=axes[2].transAxes, fontsize=12)\n",
        "    axes[2].text(0.5, 0.3, f'Training Time: {training_duration:.1f} min', \n",
        "                ha='center', va='center', transform=axes[2].transAxes, fontsize=12)\n",
        "    axes[2].set_xticks([])\n",
        "    axes[2].set_yticks([])\n",
        "    axes[2].set_title('Summary')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"üìä Training completed successfully!\")\n",
        "    print(f\"üéØ Final distance error: {final_val_distance_error:.3f} px\")\n",
        "else:\n",
        "    print(\"üìä No training history to plot\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üíæ Auto-Save Results to Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'training_history' in locals():\n",
        "    import json\n",
        "    import shutil\n",
        "    from datetime import datetime\n",
        "    from pathlib import Path\n",
        "    \n",
        "    # Create timestamp for this validation run\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "    \n",
        "    print(\"üíæ Saving validation results to Drive...\")\n",
        "    \n",
        "    # 1. Create validation results directory\n",
        "    validation_dir = Path(f\"experiments/t250_validation_{timestamp}\")\n",
        "    validation_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # 2. Save validation summary\n",
        "    validation_results = {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'experiment_type': 'T250_hyperparameter_validation',\n",
        "        'dataset': 'wave_dataset_T250.h5',\n",
        "        'hyperparameters': {\n",
        "            'learning_rate': config.learning_rate,\n",
        "            'batch_size': config.batch_size,\n",
        "            'optimizer': config.optimizer,\n",
        "            'weight_decay': config.weight_decay\n",
        "        },\n",
        "        'training_config': {\n",
        "            'epochs': config.num_epochs,\n",
        "            'early_stopping_patience': config.early_stopping_patience,\n",
        "            'model_name': config.model_name\n",
        "        },\n",
        "        'results': {\n",
        "            'final_train_loss': float(final_train_loss),\n",
        "            'final_val_loss': float(final_val_loss),\n",
        "            'final_distance_error': float(final_val_distance_error),\n",
        "            'best_epoch': int(best_epoch),\n",
        "            'training_time_minutes': float(training_duration)\n",
        "        },\n",
        "        'recommendation': recommendation,\n",
        "        'comparison': {\n",
        "            't500_grid_search_best': 2.37,\n",
        "            't500_cv_average': 2.078,\n",
        "            't250_validation': float(final_val_distance_error)\n",
        "        },\n",
        "        'mlflow_experiment_name': config.experiment_name,\n",
        "        'mlflow_run_name': config.run_name\n",
        "    }\n",
        "    \n",
        "    # Save summary JSON\n",
        "    summary_file = validation_dir / f\"validation_summary_{timestamp}.json\"\n",
        "    with open(summary_file, 'w') as f:\n",
        "        json.dump(validation_results, f, indent=2)\n",
        "    \n",
        "    print(f\"‚úÖ Summary saved: {summary_file}\")\n",
        "    \n",
        "    # 3. Save training curves plot\n",
        "    if 'fig' in locals():\n",
        "        plot_file = validation_dir / f\"training_curves_{timestamp}.png\"\n",
        "        fig.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
        "        print(f\"‚úÖ Plots saved: {plot_file}\")\n",
        "    \n",
        "    # 4. Copy MLflow experiment data\n",
        "    mlflow_backup_dir = validation_dir / \"mlflow_backup\"\n",
        "    mlflow_backup_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    # Find the MLflow experiment\n",
        "    mlflow_dir = Path(\"mlruns\")\n",
        "    if mlflow_dir.exists():\n",
        "        # Copy the relevant experiment folder\n",
        "        for exp_dir in mlflow_dir.iterdir():\n",
        "            if exp_dir.is_dir() and exp_dir.name != \"0\":\n",
        "                # Copy the entire experiment folder\n",
        "                backup_exp_dir = mlflow_backup_dir / exp_dir.name\n",
        "                if backup_exp_dir.exists():\n",
        "                    shutil.rmtree(backup_exp_dir)\n",
        "                shutil.copytree(exp_dir, backup_exp_dir)\n",
        "        print(f\"‚úÖ MLflow data backed up to: {mlflow_backup_dir}\")\n",
        "    \n",
        "    # 5. Create final report\n",
        "    report_file = validation_dir / f\"VALIDATION_REPORT_{timestamp}.md\"\n",
        "    with open(report_file, 'w') as f:\n",
        "        f.write(f\"# T=250 Hyperparameter Validation Report\\\\n\\\\n\")\n",
        "        f.write(f\"**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\\\n\\\\n\")\n",
        "        f.write(f\"## üéØ Objective\\\\n\")\n",
        "        f.write(f\"Validate winning hyperparameters on T=250 dataset before full 5-fold CV.\\\\n\\\\n\")\n",
        "        f.write(f\"## üìä Results\\\\n\")\n",
        "        f.write(f\"- **Final Distance Error**: {final_val_distance_error:.3f} px\\\\n\")\n",
        "        f.write(f\"- **Training Time**: {training_duration:.1f} minutes\\\\n\")\n",
        "        f.write(f\"- **Best Epoch**: {best_epoch}\\\\n\")\n",
        "        f.write(f\"- **Final Train Loss**: {final_train_loss:.4f}\\\\n\")\n",
        "        f.write(f\"- **Final Val Loss**: {final_val_loss:.4f}\\\\n\\\\n\")\n",
        "        f.write(f\"## üîÑ Comparison with T=500\\\\n\")\n",
        "        f.write(f\"- **T=500 Grid Search Best**: 2.37 px\\\\n\")\n",
        "        f.write(f\"- **T=500 CV Average**: 2.078 px\\\\n\")\n",
        "        f.write(f\"- **T=250 Validation**: {final_val_distance_error:.3f} px\\\\n\\\\n\")\n",
        "        f.write(f\"## üéØ Recommendation\\\\n\")\n",
        "        f.write(f\"{recommendation}\\\\n\\\\n\")\n",
        "        f.write(f\"## üìÅ Files in this validation\\\\n\")\n",
        "        f.write(f\"- `validation_summary_{timestamp}.json`: Complete results data\\\\n\")\n",
        "        f.write(f\"- `training_curves_{timestamp}.png`: Training visualizations\\\\n\")\n",
        "        f.write(f\"- `mlflow_backup/`: MLflow experiment data\\\\n\")\n",
        "        f.write(f\"- `VALIDATION_REPORT_{timestamp}.md`: This report\\\\n\")\n",
        "    \n",
        "    print(f\"‚úÖ Report saved: {report_file}\")\n",
        "    \n",
        "    print(f\"\\\\n\" + \"=\" * 60)\n",
        "    print(f\"üéâ ALL RESULTS SAVED TO DRIVE!\")\n",
        "    print(f\"üìÅ Location: {validation_dir}\")\n",
        "    print(f\"üíæ Total files saved:\")\n",
        "    saved_files = list(validation_dir.rglob(\"*\"))\n",
        "    for file in saved_files[:10]:  # Show first 10 files\n",
        "        if file.is_file():\n",
        "            print(f\"   üìÑ {file.relative_to(validation_dir)}\")\n",
        "    if len(saved_files) > 10:\n",
        "        print(f\"   ... and {len(saved_files) - 10} more files\")\n",
        "    \n",
        "    print(f\"\\\\nüîÑ Results are automatically synced to Google Drive!\")\n",
        "    print(f\"üîó You can access them anytime from Drive.\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No training results to save - training may have failed\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîÑ Runtime Management & Recovery\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Runtime management and auto-save protection\n",
        "import signal\n",
        "import atexit\n",
        "\n",
        "def emergency_save():\n",
        "    \"\"\"Emergency save function in case of runtime interruption.\"\"\"\n",
        "    try:\n",
        "        if 'trainer' in globals() and hasattr(trainer, 'save_checkpoint'):\n",
        "            checkpoint_path = f\"emergency_checkpoint_{datetime.now().strftime('%Y%m%d_%H%M')}.pt\"\n",
        "            trainer.save_checkpoint(checkpoint_path)\n",
        "            print(f\"üö® Emergency checkpoint saved: {checkpoint_path}\")\n",
        "        \n",
        "        # Save any partial results\n",
        "        if 'config' in globals():\n",
        "            emergency_dir = Path(f\"emergency_backup_{datetime.now().strftime('%Y%m%d_%H%M')}\")\n",
        "            emergency_dir.mkdir(exist_ok=True)\n",
        "            \n",
        "            emergency_info = {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'status': 'interrupted',\n",
        "                'config': {\n",
        "                    'learning_rate': config.learning_rate,\n",
        "                    'batch_size': config.batch_size,\n",
        "                    'optimizer': config.optimizer,\n",
        "                    'dataset_path': config.dataset_path,\n",
        "                    'experiment_name': config.experiment_name,\n",
        "                    'run_name': config.run_name\n",
        "                }\n",
        "            }\n",
        "            \n",
        "            with open(emergency_dir / \"emergency_info.json\", 'w') as f:\n",
        "                json.dump(emergency_info, f, indent=2)\n",
        "            \n",
        "            print(f\"üö® Emergency info saved: {emergency_dir}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Emergency save failed: {e}\")\n",
        "\n",
        "# Register emergency save\n",
        "atexit.register(emergency_save)\n",
        "\n",
        "# Keep runtime alive function\n",
        "def keep_alive():\n",
        "    \"\"\"Prevent runtime disconnection during training.\"\"\"\n",
        "    import time\n",
        "    print(\"üîÑ Runtime keep-alive activated\")\n",
        "    print(\"üí° Tip: Keep this tab active and check back periodically\")\n",
        "    \n",
        "    # Show progress indicators\n",
        "    print(\"\\\\nüìä Training Progress Indicators:\")\n",
        "    print(\"‚úÖ Watch for MLflow logging messages\")\n",
        "    print(\"‚úÖ Monitor GPU memory usage\")\n",
        "    print(\"‚úÖ Check validation loss improvements\")\n",
        "    print(\"\\\\n‚è∞ Expected milestones:\")\n",
        "    print(\"   10 min: Initial convergence\")\n",
        "    print(\"   30 min: Stable training\")\n",
        "    print(\"   60 min: Best model selection\")\n",
        "    print(\"   120 min: Training completion\")\n",
        "\n",
        "keep_alive()\n",
        "\n",
        "print(\"\\\\nüõ°Ô∏è Runtime protection activated!\")\n",
        "print(\"üì± The notebook will auto-save progress and handle interruptions gracefully.\")\n",
        "print(\"üöÄ Ready to start validation training!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract and analyze results\n",
        "if 'training_history' in locals():\n",
        "    # Extract final results\n",
        "    final_train_loss = training_history['train_loss'][-1]\n",
        "    final_val_loss = training_history['val_loss'][-1]\n",
        "    final_val_distance_error = training_history['val_distance_error'][-1]\n",
        "    best_epoch = training_history.get('best_epoch', len(training_history['val_loss']))\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"üéâ VALIDATION TRAINING COMPLETE!\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    print(f\"‚è±Ô∏è Training Time: {training_duration:.1f} minutes\")\n",
        "    print(f\"üèÜ Best Epoch: {best_epoch}\")\n",
        "    print(f\"üìä Final Results:\")\n",
        "    print(f\"   Training Loss: {final_train_loss:.4f}\")\n",
        "    print(f\"   Validation Loss: {final_val_loss:.4f}\")\n",
        "    print(f\"   Distance Error: {final_val_distance_error:.3f} px\")\n",
        "    \n",
        "    # Performance assessment\n",
        "    print(f\"\\nüìà Performance Assessment:\")\n",
        "    if final_val_distance_error <= 2.0:\n",
        "        print(f\"   ‚úÖ EXCELLENT: {final_val_distance_error:.3f} px (‚â§ 2.0 px)\")\n",
        "        recommendation = \"‚úÖ RECOMMENDED: Proceed with full 5-fold CV training\"\n",
        "    elif final_val_distance_error <= 3.0:\n",
        "        print(f\"   ‚úÖ GOOD: {final_val_distance_error:.3f} px (‚â§ 3.0 px)\")\n",
        "        recommendation = \"‚úÖ RECOMMENDED: Proceed with full 5-fold CV training\"\n",
        "    elif final_val_distance_error <= 4.0:\n",
        "        print(f\"   ‚ö†Ô∏è ACCEPTABLE: {final_val_distance_error:.3f} px (‚â§ 4.0 px)\")\n",
        "        recommendation = \"‚ö†Ô∏è CONSIDER: Maybe adjust hyperparameters or proceed with caution\"\n",
        "    else:\n",
        "        print(f\"   ‚ùå CONCERNING: {final_val_distance_error:.3f} px (> 4.0 px)\")\n",
        "        recommendation = \"‚ùå RECOMMEND: Consider hyperparameter tuning before full CV\"\n",
        "    \n",
        "    # Comparison with T=500 results\n",
        "    print(f\"\\nüîÑ Comparison with T=500 Results:\")\n",
        "    print(f\"   T=500 Grid Search Best: 2.37 px\")\n",
        "    print(f\"   T=500 CV Average: 2.078 px\")\n",
        "    print(f\"   T=250 Validation: {final_val_distance_error:.3f} px\")\n",
        "    \n",
        "    if final_val_distance_error < 2.5:\n",
        "        print(\"   ‚úÖ T=250 performance is competitive with T=500!\")\n",
        "    elif final_val_distance_error < 3.5:\n",
        "        print(\"   ‚úÖ T=250 performance is reasonable compared to T=500\")\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è T=250 performance is worse than T=500 - consider investigation\")\n",
        "    \n",
        "    print(f\"\\nüéØ RECOMMENDATION:\")\n",
        "    print(f\"   {recommendation}\")\n",
        "    \n",
        "    if \"RECOMMENDED\" in recommendation:\n",
        "        print(f\"\\nüöÄ Next Steps:\")\n",
        "        print(f\"   1. Run full 5-fold CV training on T=250 dataset\")\n",
        "        print(f\"   2. Use same hyperparameters: lr=0.001, bs=32, adam\")\n",
        "        print(f\"   3. Expected full CV time: ~10 hours\")\n",
        "        print(f\"   4. Expected CV performance: ~{final_val_distance_error:.1f} ¬± 0.3 px\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üéâ Validation complete! Check results above for next steps.\")\n",
        "else:\n",
        "    print(\"‚ùå No training history available - training may have failed\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
