# ResNet Grid Search Optimization - Phase 1
# 2x2x2 = 8 experiments to find best hyperparameter combination
# Phase 2 (later): 5-fold CV on the winning combination

experiment_name: "resnet_grid_search_phase1"
description: "2x2x2 Grid Search: Learning Rate × Batch Size × Optimizer"

# Dataset configuration
dataset_config:
  dataset_path: "/content/drive/MyDrive/Physics_Informed_DL_Project/datasets/wave_dataset_T500.h5"
  train_val_split: 0.85  # Simple split, no CV yet
  
# Base configuration (fixed for all experiments)
base_config:
  num_epochs: 50
  device: "cuda"
  save_checkpoints: true
  early_stopping_patience: 12
  
  # Fixed hyperparameters
  weight_decay: 0.01
  scheduler_type: "cosine"
  scheduler_params:
    T_max: 50
    eta_min: 0.00001
  
  # Model architecture (fixed)
  model_config:
    input_channels: 1
    hidden_channels: [16, 32, 64]
    kernel_sizes: [7, 5, 3]
    num_residual_blocks: [2, 2, 2]
    dropout_rate: 0.1

# Grid Search Parameters (2x2x2 = 8 combinations)
grid_search:
  learning_rate: [0.001, 0.0001]     # 2 options
  batch_size: [16, 32]               # 2 options
  optimizer: ["adam", "adamw"]       # 2 options

# Expected resource usage
resource_estimates:
  time_per_experiment: "45 minutes"
  total_time: "6 hours"
  gpu_memory: "8-12 GB"
  
# Success criteria
success_criteria:
  target_distance_error: "< 3.0 px"
  target_val_loss: "< 0.05"
  
# All 8 experiment combinations (auto-generated from grid)
experiments:
  - name: "exp_001_lr001_bs16_adam"
    learning_rate: 0.001
    batch_size: 16
    optimizer: "adam"
    
  - name: "exp_002_lr001_bs16_adamw"
    learning_rate: 0.001
    batch_size: 16
    optimizer: "adamw"
    
  - name: "exp_003_lr001_bs32_adam"
    learning_rate: 0.001
    batch_size: 32
    optimizer: "adam"
    
  - name: "exp_004_lr001_bs32_adamw"
    learning_rate: 0.001
    batch_size: 32
    optimizer: "adamw"
    
  - name: "exp_005_lr0001_bs16_adam"
    learning_rate: 0.0001
    batch_size: 16
    optimizer: "adam"
    
  - name: "exp_006_lr0001_bs16_adamw"
    learning_rate: 0.0001
    batch_size: 16
    optimizer: "adamw"
    
  - name: "exp_007_lr0001_bs32_adam"
    learning_rate: 0.0001
    batch_size: 32
    optimizer: "adam"
    
  - name: "exp_008_lr0001_bs32_adamw"
    learning_rate: 0.0001
    batch_size: 32
    optimizer: "adamw" 